<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Qiang Xu </title> <meta name="author" content="Qiang Xu"> <meta name="description" content="Developer Technology Engineer at NVIDIA. "> <meta name="keywords" content="qiang, xu, qiangxu1996, qiangx, xu1201, nvidia, purdue, ustc"> <meta property="og:site_name" content="Qiang Xu"> <meta property="og:type" content="website"> <meta property="og:title" content="Qiang Xu | about"> <meta property="og:url" content="https://qiangxu1996.github.io/"> <meta property="og:description" content="Developer Technology Engineer at NVIDIA. "> <meta property="og:image" content="qiang-xu.jpg"> <meta property="og:locale" content="en"> <meta name="twitter:card" content="summary"> <meta name="twitter:title" content="about"> <meta name="twitter:description" content="Developer Technology Engineer at NVIDIA. "> <meta name="twitter:image" content="qiang-xu.jpg"> <script type="application/ld+json">
    {
        "author":
        {
            "@type": "Person",
            "name": "Qiang Xu"
        },
        "url": "https://qiangxu1996.github.io/",
        "@type": "WebSite",
        "description": "Developer Technology Engineer at NVIDIA.
",
        "headline": "about",
        
        "sameAs": ["https://github.com/qiangxu1996","https://www.linkedin.com/in/qiang-xu-641982152","https://scholar.google.com/citations?user=WX638_wAAAAJ",null],
        
        "name": "Qiang Xu",
        "@context": "https://schema.org"
    }
  </script> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link rel="shortcut icon" href="/assets/img/favicon.ico?300a10646eba75c4501023cebdc683cb"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://qiangxu1996.github.io/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title" href="/"> Qiang Xu </a> <div class="text-right"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <div class="row"> <div class="col-6 offset-1 col-sm-4 offset-sm-0 col-md-3"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/qiang-xu-480.webp 480w,/assets/img/qiang-xu-800.webp 800w,/assets/img/qiang-xu-1400.webp 1400w," type="image/webp" sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img/qiang-xu.jpg?998505976bfe10e1739dfdb41b1d199a" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="qiang-xu.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div class="w-100 d-block d-sm-none"></div> <div class="col offset-1 offset-sm-0 d-flex flex-column justify-content-between"> <div class="more-info"> <h1>Qiang Xu, Ph.D.</h1> <p> Developer Technology Engineer<br> NVIDIA </p> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%71%69%61%6E%67%78@%6E%76%69%64%69%61.%63%6F%6D" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://github.com/qiangxu1996" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://www.linkedin.com/in/qiang-xu-641982152" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="https://scholar.google.com/citations?user=WX638_wAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="/assets/qiang-xu-cv.pdf" title="curriculum vitae"><i class="ai ai-cv"></i></a> </div> </div> </div> </div> </header> <article> <div class="clearfix"> <p>I am a Developer Technology Engineer at <a href="https://www.nvidia.com/en-us/" rel="external nofollow noopener" target="_blank">NVIDIA</a>. I am interested in mobile systems, edge computing, and their intersection with machine learning. My recent research focuses on building efficient machine learning inference systems for emerging applications like augmented reality and large language models. I obtained my Ph.D. in Electrical and Computer Engineering from <a href="https://www.purdue.edu/" rel="external nofollow noopener" target="_blank">Purdue University</a> in 2024, supervised by <a href="https://engineering.purdue.edu/~ychu/" rel="external nofollow noopener" target="_blank">Prof. Y. Charlie Hu</a>. I received my B.E. in Computer Science and Technology from <a href="https://en.ustc.edu.cn/" rel="external nofollow noopener" target="_blank">University of Science and Technology of China (USTC)</a> in 2018.</p> </div> <h2> News </h2> <div class="news"> <div class="table-responsive"> <table class="table table-sm table-borderless"> <tr> <th scope="row">Apr, 2025</th> <td> PPipe accepted to USENIX ATC 2025! </td> </tr> <tr> <th scope="row">Jan, 2025</th> <td> I will be presenting our EdgeSync paper at PeRConAI 2025! </td> </tr> <tr> <th scope="row">Jun, 2024</th> <td> I have graduated from Purdue University and will be joining <a href="https://www.nvidia.com/en-us/" rel="external nofollow noopener" target="_blank">NVIDIA</a> soon! </td> </tr> <tr> <th scope="row">Mar, 2024</th> <td> ARISE accepted to MobiSys 2024! </td> </tr> <tr> <th scope="row">Feb, 2023</th> <td> I will be interning at <a href="https://www.nec-labs.com/" rel="external nofollow noopener" target="_blank">NEC Labs</a> this summer! </td> </tr> </table> </div> </div> <h2> Publications </h2> <div class="publications"> <ol class="bibliography"> <li> <div id="zhang2025dissectingimpactmobiledvfs"> <div class="title"> Dissecting the Impact of Mobile DVFS Governors on LLM Inference Performance and Energy Efficiency <a href="https://arxiv.org/pdf/2507.02135" rel="external nofollow noopener" target="_blank"><i class="fas fa-file-pdf"></i></a> </div> <div class="author"> Zongpu Zhang, Pranab Dash, Y. Charlie Hu, <strong>Qiang Xu</strong>, Jian Li, and Haibing Guan </div> <div class="periodical"> <em>Preprint</em>, 2025 </div> </div> </li> <li> <div id="kong2025ppipe"> <div class="title"> PPipe: Efficient Video Analytics Serving on Heterogeneous GPU Clusters via Pool-Based Pipeline Parallelism <a href="https://arxiv.org/pdf/2507.18748" rel="external nofollow noopener" target="_blank"><i class="fas fa-file-pdf"></i></a> <a href="https://github.com/JonnyKong/PPipe" rel="external nofollow noopener" target="_blank"><i class="fas fa-file-code"></i></a> </div> <div class="author"> Z. Jonny Kong<sup>*</sup>, <strong>Qiang Xu<sup>*</sup></strong>, and Y. Charlie Hu (* co-primary) </div> <div class="periodical"> <em>2025 USENIX Annual Technical Conference</em> (<strong>USENIX ATC 2025</strong>) </div> </div> </li> <li> <div id="11038680"> <div class="title"> EdgeSync: Efficient Edge-Assisted Video Analytics via Network Contention-Aware Scheduling </div> <div class="author"> <strong>Qiang Xu</strong>, Ravi K. Rajendran, Murugan Sankaradas, and Srimat T. Chakradhar </div> <div class="periodical"> <em> 4th IEEE Workshop on Pervasive and Resource-constrained Artificial Intelligence </em> (<strong>PeRConAI 2025</strong>) </div> <div class="abstract hidden"> <p> With the advancement of 5G, edge-assisted video analytics has become increasingly popular, driven by the technologyâ€™s ability to support low-latency, high-bandwidth applications. However, in scenarios where multiple clients competing for network resources, network contention poses a significant challenge. In this paper, we propose a novel scheduling algorithm that intelligently batches and aligns the offloading of multiple video analytics clients to optimize both network and edge server resource utilization while meeting the Service Level Objective (SLO). Experiment with a cellular network testbed shows that our approach successfully processes 93% or more of inference requests from 7 different clients to the edge server while meeting the SLOs, whereas other approaches achieve a lower success rate, ranging from 65% to 85% under the same condition. </p> </div> </div> </li> <li> <div id="Xu2024"> <div class="title"> Towards High-Accuracy and Resource-Efficient Edge-Assisted Augmented Reality <a href="https://hammer.purdue.edu/ndownloader/files/47821255" rel="external nofollow noopener" target="_blank"><i class="fas fa-file-pdf"></i></a> </div> <div class="author"> <strong>Qiang Xu</strong> </div> <div class="periodical"> <em>Purdue University</em>, 2024 </div> </div> </li> <li> <div id="10.1145/3643832.3661894"> <div class="title"> ARISE: High-Capacity AR Offloading Inference Serving via Proactive Scheduling <a href="https://dl.acm.org/doi/10.1145/3643832.3661894" rel="external nofollow noopener" target="_blank"><i class="fas fa-file-pdf"></i></a> </div> <div class="author"> Z. Jonny Kong<sup>*</sup>, <strong>Qiang Xu<sup>*</sup></strong>, and Y. Charlie Hu (* co-primary) </div> <div class="periodical"> <em>The 22nd Annual International Conference on Mobile Systems, Applications and Services</em> (<strong>MobiSys 2024</strong>) </div> <div class="abstract hidden"> <p>With faster wireless networks and server GPUs, offloading high-accuracy but compute-intensive AR tasks implemented in Deep Neural Networks (DNNs) to edge servers offers a promising way to support high-QoE Augmented/Mixed Reality (AR/MR) applications. A cost-effective way for AR app vendors to deploy such edge-assisted AR apps to support a large user base is to use commercial Machine-Learning-as-a-Service (MLaaS) deployed at the edge cloud. To maximize cost-effectiveness, such an MLaaS provider faces a key design challenge, i.e., how to maximize the number of clients concurrently served by each GPU server in its cluster while meeting per-client AR task accuracy SLAs. The above AR offloading inference serving problem differs from generic inference serving or video analytics serving in one fundamental way: due to the use of local tracking which reuses the last server-returned inference result to derive results for the current frame, the offloading frequency and end-to-end latency of each AR client directly affect its AR task accuracy (for all the frames).In this paper, we present ARISE, a framework that optimizes the edge server capacity in serving edge-assisted AR clients. Our design exploits the intricate interplay between per-client offloading schedule and batched inference on the server via proactively coordinating offloading request streams from different AR clients. Our evaluation using a large set of emulated AR clients and a 10-phone testbed shows that ARISE supports 1.7xâ€“6.9x more clients compared to various baselines while keeping the per-client accuracy within the client-specified accuracy SLAs.</p> </div> </div> </li> <li> <div id="10387645"> <div class="title"> Can 5G mmWave Enable Edge-Assisted Real-Time Object Detection for Augmented Reality? <a href="/assets/pdf/paper_18.pdf"><i class="fas fa-file-pdf"></i></a> </div> <div class="author"> Moinak Ghoshal<sup>*</sup>, Z. Jonny Kong<sup>*</sup>, <strong>Qiang Xu<sup>*</sup></strong>, Zixiao Lu, Shivang Aggarwal, Imran Khan, Jiayi Meng, Yuanjie Li, Y. Charlie Hu, and Dimitrios Koutsonikolas (* co-primary) </div> <div class="periodical"> <em>31st International Symposium on Modeling, Analysis, and Simulation of Computer and Telecommunication Systems</em> (<strong>MASCOTS 2023</strong>) </div> </div> </li> <li> <div id="10.1145/3570361.3592531"> <div class="title"> AccuMO: Accuracy-Centric Multitask Offloading in Edge-Assisted Mobile Augmented Reality <a href="/assets/pdf/mobicom23-final448.pdf"><i class="fas fa-file-pdf"></i></a> <a href="https://github.com/JonnyKong/AccuMO" rel="external nofollow noopener" target="_blank"><i class="fas fa-file-code"></i></a> </div> <div class="author"> Z. Jonny Kong<sup>*</sup>, <strong>Qiang Xu<sup>*</sup></strong>, Jiayi Meng, and Y. Charlie Hu (* co-primary) </div> <div class="periodical"> <em>The 29th Annual International Conference on Mobile Computing and Networking</em> (<strong>MobiCom 2023</strong>) </div> <div class="abstract hidden"> <p>Immersive applications such as Augmented Reality (AR) and Mixed Reality (MR) often need to perform multiple latency-critical tasks on every frame captured by the camera, which all require results to be available within the current frame interval. While such tasks are increasingly supported by Deep Neural Networks (DNNs) offloaded to edge servers due to their high accuracy but heavy computation, prior work has largely focused on offloading one task at a time. Compared to offloading a single task, where more frequent offloading directly translates into higher task accuracy, offloading of multiple tasks competes for shared edge server resources, and hence faces the additional challenge of balancing the offloading frequencies of different tasks to maximize the overall accuracy and hence app QoE.In this paper, we formulate this accuracy-centric multitask offloading problem, and present a framework that dynamically schedules the offloading of multiple DNN tasks from a mobile device to an edge server while optimizing the overall accuracy across tasks. Our design employs two novel ideas: (1) task-specific lightweight models that predict offloading accuracy drop as a function of offloading frequency and frame content, and (2) a general two-level control feedback loop that concurrently balances offloading among tasks and adapts between offloading and using local algorithms for each task. Evaluation results show that our framework improves the overall accuracy significantly in jointly offloading two core tasks in AR â€” depth estimation and odometry â€” by on average 7.6%â€“14.3% over the best baselines under different accuracy weight ratios.</p> </div> </div> </li> <li> <div id="10.1145/3538394.3546042"> <div class="title"> An In-Depth Study of Uplink Performance of 5G MmWave Networks <a href="/assets/pdf/memu-5g22-final56.pdf"><i class="fas fa-file-pdf"></i></a> <a href="https://github.com/NUWiNS/sigcomm-5gmemu-5g-mmWave-uplink-data" rel="external nofollow noopener" target="_blank"><i class="fas fa-file-code"></i></a> </div> <div class="author"> Moinak Ghoshal<sup>*</sup>, Z. Jonny Kong<sup>*</sup>, <strong>Qiang Xu<sup>*</sup></strong>, Zixiao Lu, Shivang Aggarwal, Imran Khan, Yuanjie Li, Y. Charlie Hu, and Dimitrios Koutsonikolas (* co-primary) </div> <div class="periodical"> <em>The 2nd ACM SIGCOMM Workshop on 5G and Beyond Network Measurements, Modeling, and Use Cases</em> (<strong>5G-MeMU 2022</strong>) </div> <div class="abstract hidden"> <p>The highly anticipated 5G mmWave technology promises to enable many uplink-oriented, latency-critical applications (LCAs) such as Augmented Reality and Connected Autonomous Vehicles. Nonetheless, recent measurement studies have largely focused on its downlink performance. In this work, we perform a systematic study of the uplink performance of commercial 5G mmWave networks across 3 major US cities and 2 mobile operators. Our study makes three contributions. (1) It reveals that 5G mmWave uplink performance is geographically diverse, substantially higher over LTE in terms of bandwidth and latency, but often erratic and suboptimal, which can degrade LCA performance. (2) Our analysis of control messages and PHY-level KPIs shows that the root causes for the suboptimal performance are fundamental to 5G mmWave and cannot be easily fixed via simple tuning of network configurations. (3) We identify various design and deployment optimizations that 5G operators can explore to bring 5G mmWave performance to the level needed to ultimately support the LCAs.</p> </div> </div> </li> <li> <div id="10.1007/978-3-030-98785-5_8"> <div class="title"> Can 5G mmWave Support Multi-user AR? <a href="/assets/pdf/pam2022-final64.pdf"><i class="fas fa-file-pdf"></i></a> <a href="https://github.com/NUWiNS/pam2022-5G-mmwave-multi-user-ar-data" rel="external nofollow noopener" target="_blank"><i class="fas fa-file-code"></i></a> </div> <div class="author"> Moinak Ghoshal, Pranab Dash, Z. Jonny Kong, <strong>Qiang Xu</strong>, Y. Charlie Hu, Dimitrios Koutsonikolas, and Yuanjie Li </div> <div class="periodical"> <em>Passive and Active Measurement Conference 2022</em> (<strong>PAM 2022</strong>) </div> <div class="abstract hidden"> <p>Augmented Reality (AR) has been widely hailed as a representative of ultra-high bandwidth and ultra-low latency apps that will be enabled by 5G networks. While single-user AR can perform AR tasks locally on the mobile device, multi-user AR apps, which allow multiple users to interact within the same physical space, critically rely on the cellular network to support user interactions. However, a recent study showed that multi-user AR apps can experience very high end-to-end latency when running over LTE, rendering user interaction practically infeasible. In this paper, we study whether 5G mmWave, which promises significant bandwidth and latency improvements over LTE, can support multi-user AR by conducting an in-depth measurement study of the same popular multi-user AR app over both LTE and 5G mmWave.</p> </div> </div> </li> <li> <div id="9825870"> <div class="title"> An Empirical Study on the Impact of Deep Parameters on Mobile App Energy Usage <a href="https://arxiv.org/pdf/2009.12156" rel="external nofollow noopener" target="_blank"><i class="fas fa-file-pdf"></i></a> <a href="https://github.com/qiangxu1996/literal-mutator" rel="external nofollow noopener" target="_blank"><i class="fas fa-file-code"></i></a> </div> <div class="author"> <strong>Qiang Xu</strong>, James C. Davis, Y. Charlie Hu, and Abhilash Jindal </div> <div class="periodical"> <em>The 29th IEEE International Conference on Software Analysis, Evolution and Reengineering</em> (<strong>SANER 2022</strong>) </div> </div> </li> <li> <div id="10.1145/3472727.3472807"> <div class="title"> Do Larger (More Accurate) Deep Neural Network Models Help in Edge-Assisted Augmented Reality? <a href="/assets/pdf/nai21-final73.pdf"><i class="fas fa-file-pdf"></i></a> </div> <div class="author"> Jiayi Meng, Z. Jonny Kong, <strong>Qiang Xu</strong>, and Y. Charlie Hu </div> <div class="periodical"> <em>ACM SIGCOMM 2021 Workshop on Network-Application Integration</em> (<strong>NAI 2021</strong>) </div> <div class="abstract hidden"> <p>Edge-assisted Augmented Reality (AR) which offloads compute-intensive Deep Neural Network (DNN)-based AR tasks to edge servers faces an important design challenge: how to pick the DNN model out of many choices proposed for each AR task for offloading. For each AR task, e.g., depth estimation, many DNN-based models have been proposed over time that vary in accuracy and complexity. In general, more accurate models are also more complex; they are larger and have longer inference time. Thus choosing a larger model in offloading can provide higher accuracy for the offloaded frames but also incur longer turnaround time, during which the AR app has to reuse the estimation result from the last offloaded frame, which can lead to lower average accuracy.In this paper, we experimentally study this design tradeoff using depth estimation as a case study. We design optimal offloading schedule and further consider the impact of numerous factors such as on-device fast tracking, frame downsizing and available network bandwidth. Our results show that for edge-assisted monocular depth estimation, with proper frame downsizing and fast tracking, compared to small models, the improved accuracy of large models can offset its longer turnaround time to provide higher average estimation accuracy across frames under both LTE and 5G mmWave.</p> </div> </div> </li> <li> <div id="273877"> <div class="title"> Proactive Energy-Aware Adaptive Video Streaming on Mobile Devices <a href="/assets/pdf/atc21-final288.pdf"><i class="fas fa-file-pdf"></i></a> <a href="https://github.com/meng72/Proactive-Energy-Aware-Adaptive-Video-Streaming" rel="external nofollow noopener" target="_blank"><i class="fas fa-file-code"></i></a> </div> <div class="author"> Jiayi Meng, <strong>Qiang Xu</strong>, and Y. Charlie Hu </div> <div class="periodical"> <em>2021 USENIX Annual Technical Conference</em> (<strong>USENIX ATC 2021</strong>) </div> </div> </li> </ol> </div> <h2> Professional Services </h2> <ul> <li>Journal reviewer: <a href="https://www.computer.org/csdl/journal/tm" rel="external nofollow noopener" target="_blank">IEEE Transactions on Mobile Computing</a> </li> </ul> </article> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Last updated: August 28, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-2XZXX3RQEW"></script> <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() {
      dataLayer.push(arguments);
    }
    gtag('js', new Date());

    gtag('config', 'G-2XZXX3RQEW');
  </script> <script defer src="/assets/js/google-analytics-setup.js"></script> </body> </html>